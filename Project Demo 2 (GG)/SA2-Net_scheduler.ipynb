{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgg39RIwQO1T",
        "outputId": "ef1c56e1-4896-4641-fa34-e4fbd51b34d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgg6PpJVna2x"
      },
      "outputs": [],
      "source": [
        "# extract data from zip file\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to your zip file and the directory where you want to extract it\n",
        "zip_file_path = '/content/drive/MyDrive/465 Project/new_archive.zip'\n",
        "extract_folder_path = '/content/data'\n",
        "\n",
        "os.makedirs(extract_folder_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "_jbuq7iE354B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz7G45_MVilc"
      },
      "outputs": [],
      "source": [
        "# lib imports\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQf8GJC3WxBu"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "IMG_CHANNELS = 3\n",
        "IMG_COUNT = 480"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB9yUggrZ5u5"
      },
      "outputs": [],
      "source": [
        "# set this between [1, 10] for differently composed datasets\n",
        "# reference: https://arxiv.org/pdf/2307.05911.pdf\n",
        "TRAINING_SET = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model : Sa2Net from Github"
      ],
      "metadata": {
        "id": "FjF_W7tA4BDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mustansarfiaz/SA2-Net/main/SegPC2021_ISIC2018/models/mynet/sasanet.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUUC22X24IOA",
        "outputId": "f06d756f-01c6-409e-bd45-1e6986ca4fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-29 12:54:56--  https://raw.githubusercontent.com/mustansarfiaz/SA2-Net/main/SegPC2021_ISIC2018/models/mynet/sasanet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15648 (15K) [text/plain]\n",
            "Saving to: ‘sasanet.py’\n",
            "\n",
            "\rsasanet.py            0%[                    ]       0  --.-KB/s               \rsasanet.py          100%[===================>]  15.28K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-04-29 12:54:56 (25.7 MB/s) - ‘sasanet.py’ saved [15648/15648]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sasanet import MyNet\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = MyNet(n_channels=3, base_channel=64, n_classes=1, img_size=224).to(device)\n"
      ],
      "metadata": {
        "id": "nqCXKZa2qjw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate total parameters\n",
        "# total_params = sum(p.numel() for p in model.parameters())\n",
        "# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "# non_trainable_params = total_params - trainable_params\n",
        "\n",
        "# # Output the parameter counts\n",
        "# print(f\"Total parameters: {total_params}\")\n",
        "# print(f\"Trainable parameters: {trainable_params}\")\n",
        "# print(f\"Non-trainable parameters: {non_trainable_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulnvNv-WQSbb",
        "outputId": "3d82c514-a4ca-4e32-c3ea-03d0e6e3a82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 32484308\n",
            "Trainable parameters: 32484308\n",
            "Non-trainable parameters: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IawsoiuQBxU3"
      },
      "source": [
        "# Dataset splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRB5U53vS6NK"
      },
      "source": [
        "# TestSets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBIq7T3LOx9W",
        "outputId": "16374636-3eae-4a92-d0ec-dc71bcebb023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Training Set 1: Manually Segmented - 100% (480)\n",
            "Loaded images and masks count: 480\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "class GrainDataHandler:\n",
        "    def __init__(self, image_dir, mask_dir, img_width, img_height, training_set=1):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.target_size = (img_width, img_height)\n",
        "        self.training_set = training_set\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "\n",
        "    def load_data(self):\n",
        "        if self.training_set == 1:\n",
        "            print(\"Selected Training Set 1: Manually Segmented - 100% (480)\")\n",
        "            self.images = [self.process_file(os.path.join(self.image_dir, file)) for file in sorted(os.listdir(self.image_dir))]\n",
        "            self.masks = [self.process_file(os.path.join(self.mask_dir, file), mask=True) for file in sorted(os.listdir(self.mask_dir))]\n",
        "            print(f\"Loaded images and masks count: {len(self.images)}\")\n",
        "\n",
        "    def process_file(self, file_path, mask=False):\n",
        "        img = cv2.imread(file_path)\n",
        "        img = cv2.resize(img, self.target_size)\n",
        "        if mask:\n",
        "            img = np.where(img > 245, True, False)\n",
        "            img = np.any(img, axis=2).astype(float)\n",
        "            return img.reshape(1, *self.target_size)\n",
        "        return np.transpose(img, (2, 0, 1))\n",
        "\n",
        "    def split_dataset(self, split_ratio=(0.8, 0.1, 0.1)):\n",
        "        dataset = GrainDataset(np.array(self.images), np.array(self.masks))\n",
        "        total_count = len(dataset)\n",
        "        train_count = int(split_ratio[0] * total_count)\n",
        "        val_count = int(split_ratio[1] * total_count)\n",
        "        test_count = total_count - train_count - val_count\n",
        "        return random_split(dataset, [train_count, val_count, test_count])\n",
        "\n",
        "class GrainDataset(Dataset):\n",
        "    def __init__(self, images, masks):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.from_numpy(self.images[idx]).float()\n",
        "        mask = torch.from_numpy(self.masks[idx]).float()\n",
        "        return image, mask\n",
        "\n",
        "# Usage\n",
        "image_dir = '/content/data/GRAIN DATA SET/RG'\n",
        "mask_dir = '/content/data/GRAIN DATA SET/RGMask'\n",
        "img_width, img_height = 224, 224  # Set your dimensions\n",
        "\n",
        "data_handler = GrainDataHandler(image_dir, mask_dir, img_width, img_height)\n",
        "data_handler.load_data()\n",
        "train_dataset, val_dataset, test_dataset = data_handler.split_dataset()\n",
        "\n",
        "# Now you can use these datasets with DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OCZkEHi61VK"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "class ModelCheckpoint:\n",
        "    def __init__(self, checkpoint_path):\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "    def __call__(self, model, epoch, train_loss, val_loss):\n",
        "        if val_loss < self.best_loss:\n",
        "            torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'train_loss' : train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            }, self.checkpoint_path)\n",
        "            print(\"Checkpoint saved\")\n",
        "            self.best_loss = val_loss\n",
        "\n",
        "from datetime import datetime\n",
        "checkpoint_path = f'/content/drive/MyDrive/465 Project/Ex1-SS316L-Grains-500X/Sa2net_diceloss_{datetime.now().strftime(\"%d%m%Y %H:%M:%S\")}.pt'\n",
        "\n",
        "# os.makedirs(\"/content/drive/MyDrive/465 Project\", exist_ok=True) # already exists\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpointer = ModelCheckpoint(checkpoint_path)"
      ],
      "metadata": {
        "id": "O30QCRPNbsDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "EPSILON = 1e-6\n",
        "\n",
        "class DiceLoss(torch.nn.Module):\n",
        "    def __init__(self,):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, mask):\n",
        "        pred = pred.flatten()\n",
        "        mask = mask.flatten()\n",
        "\n",
        "        intersect = (mask * pred).sum()\n",
        "        dice_score = 2*intersect / (pred.sum() + mask.sum() + EPSILON)\n",
        "        dice_loss = 1 - dice_score\n",
        "        return dice_loss\n"
      ],
      "metadata": {
        "id": "o12_1hDvbYXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss):\n",
        "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model...')\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "iYhpcQC88sI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1ze9oRSeFL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6b1e21-2351-442e-c913-9cffb07721c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40], Train Loss: 0.9159, Val Loss: 0.2293\n",
            "Checkpoint saved\n",
            "Validation loss decreased (inf --> 0.229293).  Saving model...\n",
            "Epoch [2/40], Train Loss: 0.7070, Val Loss: 0.2042\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.229293 --> 0.204152).  Saving model...\n",
            "Epoch [3/40], Train Loss: 0.6337, Val Loss: 0.1870\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.204152 --> 0.186952).  Saving model...\n",
            "Epoch [4/40], Train Loss: 0.5821, Val Loss: 0.1710\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.186952 --> 0.170969).  Saving model...\n",
            "Epoch [5/40], Train Loss: 0.5432, Val Loss: 0.1571\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.170969 --> 0.157124).  Saving model...\n",
            "Epoch [6/40], Train Loss: 0.5085, Val Loss: 0.1487\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.157124 --> 0.148691).  Saving model...\n",
            "Epoch [7/40], Train Loss: 0.4807, Val Loss: 0.1414\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.148691 --> 0.141356).  Saving model...\n",
            "Epoch [8/40], Train Loss: 0.4570, Val Loss: 0.1331\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.141356 --> 0.133093).  Saving model...\n",
            "Epoch [9/40], Train Loss: 0.4347, Val Loss: 0.1293\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.133093 --> 0.129263).  Saving model...\n",
            "Epoch [10/40], Train Loss: 0.4154, Val Loss: 0.1218\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.129263 --> 0.121849).  Saving model...\n",
            "Epoch [11/40], Train Loss: 0.3964, Val Loss: 0.1236\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Epoch [12/40], Train Loss: 0.3738, Val Loss: 0.1241\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Epoch [13/40], Train Loss: 0.3543, Val Loss: 0.1196\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.121849 --> 0.119632).  Saving model...\n",
            "Epoch [14/40], Train Loss: 0.3351, Val Loss: 0.1117\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.119632 --> 0.111722).  Saving model...\n",
            "Epoch [15/40], Train Loss: 0.3099, Val Loss: 0.1145\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Epoch [16/40], Train Loss: 0.2934, Val Loss: 0.1119\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Epoch [17/40], Train Loss: 0.2717, Val Loss: 0.1114\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.111722 --> 0.111404).  Saving model...\n",
            "Epoch [18/40], Train Loss: 0.2592, Val Loss: 0.1099\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.111404 --> 0.109874).  Saving model...\n",
            "Epoch [19/40], Train Loss: 0.2419, Val Loss: 0.1062\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.109874 --> 0.106180).  Saving model...\n",
            "Epoch [20/40], Train Loss: 0.2310, Val Loss: 0.1048\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.106180 --> 0.104791).  Saving model...\n",
            "Epoch [21/40], Train Loss: 0.2170, Val Loss: 0.1065\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Epoch [22/40], Train Loss: 0.2053, Val Loss: 0.1056\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Epoch [23/40], Train Loss: 0.2020, Val Loss: 0.1032\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.104791 --> 0.103237).  Saving model...\n",
            "Epoch [24/40], Train Loss: 0.1904, Val Loss: 0.1052\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Epoch [25/40], Train Loss: 0.1823, Val Loss: 0.1027\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.103237 --> 0.102661).  Saving model...\n",
            "Epoch [26/40], Train Loss: 0.1766, Val Loss: 0.1020\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.102661 --> 0.101972).  Saving model...\n",
            "Epoch [27/40], Train Loss: 0.1701, Val Loss: 0.1043\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Epoch [28/40], Train Loss: 0.1644, Val Loss: 0.1022\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Epoch [29/40], Train Loss: 0.1611, Val Loss: 0.1020\n",
            "EarlyStopping counter: 3 out of 10\n",
            "Epoch [30/40], Train Loss: 0.1584, Val Loss: 0.1007\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.101972 --> 0.100653).  Saving model...\n",
            "Epoch [31/40], Train Loss: 0.1555, Val Loss: 0.1018\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Epoch [32/40], Train Loss: 0.1508, Val Loss: 0.1010\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Epoch [33/40], Train Loss: 0.1478, Val Loss: 0.1005\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.100653 --> 0.100468).  Saving model...\n",
            "Epoch [34/40], Train Loss: 0.1433, Val Loss: 0.0988\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.100468 --> 0.098837).  Saving model...\n",
            "Epoch [35/40], Train Loss: 0.1413, Val Loss: 0.0999\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Epoch [36/40], Train Loss: 0.1400, Val Loss: 0.0990\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Epoch [37/40], Train Loss: 0.1387, Val Loss: 0.0982\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.098837 --> 0.098212).  Saving model...\n",
            "Epoch [38/40], Train Loss: 0.1353, Val Loss: 0.0977\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.098212 --> 0.097710).  Saving model...\n",
            "Epoch [39/40], Train Loss: 0.1333, Val Loss: 0.0994\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Epoch [40/40], Train Loss: 0.1311, Val Loss: 0.0975\n",
            "Checkpoint saved\n",
            "Validation loss decreased (0.097710 --> 0.097481).  Saving model...\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = DiceLoss()\n",
        "\n",
        "early_stopper = EarlyStopping(patience=10, verbose=True)\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "num_epochs = 40\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss = 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear the gradients\n",
        "        preds4, preds3, preds2, preds1 = model(inputs)\n",
        "        # Calculate loss from multiple outputs\n",
        "        loss4 = criterion(preds4, targets)\n",
        "        loss3 = criterion(preds3, targets)\n",
        "        loss2 = criterion(preds2, targets)\n",
        "        loss1 = criterion(preds1, targets)\n",
        "        loss = loss4 + loss3 + loss2 + loss1\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update parameters\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        num_samples += inputs.size(0)\n",
        "\n",
        "    train_loss /= num_samples\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    num_val_samples = 0\n",
        "    with torch.no_grad():  # Validation loop\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            preds = model(inputs)\n",
        "            val_loss += criterion(preds, targets).item() * inputs.size(0)\n",
        "            num_val_samples += inputs.size(0)\n",
        "\n",
        "        val_loss /= num_val_samples\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Scheduler step is called after updating the validation loss\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Checkpointing and early stopping\n",
        "    checkpointer(model, epoch, train_loss, val_loss)\n",
        "    early_stopper(val_loss)\n",
        "    if early_stopper.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6rODygYDo1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e632afd-2635-4658-d0ea-3c41b773dd70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13112890409926573 0.09748125076293945\n"
          ]
        }
      ],
      "source": [
        "current_checkpoint = torch.load(checkpoint_path)\n",
        "model.load_state_dict(current_checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "print(current_checkpoint['train_loss'],current_checkpoint['val_loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpointer Path"
      ],
      "metadata": {
        "id": "bRb3ECilHzOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MOiuDfyYHtkI",
        "outputId": "b807f554-cbc2-4821-8a01-7c0b3b88967e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/465 Project/Ex1-SS316L-Grains-500X/Sa2net_diceloss_29042024 12:55:01.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0iT1-GD7AUJ"
      },
      "source": [
        "# Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IraOKMDpCH1Q",
        "outputId": "03025840-3284-45b3-920d-0cb94131922b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/841.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/841.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m819.2/841.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsDjHWZf2PlR"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf1h1FTTqU23",
        "outputId": "b3d1c960-4095-41bd-f0ee-f12cf4645d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch-> 40\n",
            "Total Number samples: 48\n",
            "Average Dice Score: 0.9017558979491392\n",
            "Average Jaccard Index: 0.8214371887346109\n"
          ]
        }
      ],
      "source": [
        "from torchmetrics.functional import dice\n",
        "from torchmetrics.functional import jaccard_index\n",
        "\n",
        "total_jaccard_score = 0.0\n",
        "total_dice_score = 0.0\n",
        "total_num_samples = 0\n",
        "\n",
        "for images, masks in test_loader:\n",
        "    batch_size = images.size(0)  # Get the actual batch size\n",
        "    total_num_samples += batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        preds = model(images)\n",
        "\n",
        "        for ind in range(len(preds)):\n",
        "            pred_tensor = (preds[ind] > 0.5).float()\n",
        "            gt_tensor = masks[ind].to(torch.int64)  # Convert mask tensor to integer tensor\n",
        "\n",
        "            dice_score = dice(pred_tensor, gt_tensor)\n",
        "            total_dice_score += dice_score.item()\n",
        "\n",
        "            jaccard_score = jaccard_index(pred_tensor, gt_tensor, task='binary')\n",
        "            total_jaccard_score += jaccard_score.item()\n",
        "\n",
        "average_dice_score = total_dice_score / total_num_samples\n",
        "average_jaccard_score = total_jaccard_score / total_num_samples\n",
        "\n",
        "\n",
        "print(f\"epoch-> {num_epochs}\")\n",
        "print(f\"Total Number samples: {total_num_samples}\")\n",
        "print(f\"Average Dice Score: {average_dice_score}\")\n",
        "print(f\"Average Jaccard Index: {average_jaccard_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Checking Other Threshold values:"
      ],
      "metadata": {
        "id": "CdXgpNL9Jrt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, _ in val_loader:\n",
        "        images = images.to(device)\n",
        "        preds = model(images)\n",
        "        all_preds.extend(preds.flatten().cpu().numpy())  # Flatten and move to CPU\n",
        "\n",
        "all_preds_np = np.array(all_preds)\n",
        "\n",
        "# Plot the histogram\n",
        "plt.hist(all_preds_np, bins=50, density=True)\n",
        "plt.title('Distribution of Predicted Pixel Values')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Density')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "hYymzb_LAG29",
        "outputId": "96e5c3be-8390-4fd3-b539-d01b89d8b230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9u0lEQVR4nO3de3zP9f//8fsb23tOG8NOzLBF5RjVcj4tc0gYlRKbEKFPSFjlMCo6fER9JJ22KCk+ol9yPn4SFRERH+ZYzCHZZjKzPX9/uOz9bbaxzbb3++Vzu14ur8vF+/V6vl6vx/v53rzve76er/fbZowxAgAAsKASzi4AAACgoAgyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggycEmTJk2SzWYrlnO1adNGbdq0cTzesGGDbDabFi1aVCznj4qKUo0aNYrlXAV14cIFDRw4UH5+frLZbBoxYoSzS8pVXFycbDabjhw54lh37WvsbDnVeDOK+vkV5+/j3xV2P+HWRJBBkcv8zyhz8fDwUEBAgMLDw/XWW28pOTm5UM5z4sQJTZo0STt37iyU4xUmV64tL1555RXFxcXpqaee0rx589S3b99c29aoUSPL6+3j46OWLVvqyy+/LMaKb97Fixc1adIkbdiwwWk1ZAaIzKVMmTK688479eKLLyopKclpdV0rLS1NlStXVosWLXJtY4xRYGCgGjduXIyV4X9BKWcXgP8dkydPVs2aNZWWlqaEhARt2LBBI0aM0PTp0/XVV1+pQYMGjrYvvviixo0bl6/jnzhxQjExMapRo4YaNWqU5/1WrVqVr/MUxPVqe//995WRkVHkNdyMdevW6b777tPEiRPz1L5Ro0Z69tlnJV197nPmzFFERIRmz56tIUOGFGWpOSrIa3zx4kXFxMRIktNHc2bPnq1y5crpwoULWrVqlV5++WWtW7dOmzdvls1mK5af4etxc3PTQw89pDlz5ujo0aMKCgrK1mbTpk367bffNHLkSCdUiFsZIzIoNp06ddLjjz+u/v37Kzo6WitXrtSaNWt0+vRpPfjgg/rrr78cbUuVKiUPD48irefixYuSJHd3d7m7uxfpua7Hzc1NdrvdaefPi9OnT6tChQp5bl+1alU9/vjjevzxxzVmzBht3rxZZcuW1ZtvvpnrPleuXNHly5cLodrsnP0a36xevXrp8ccf15AhQ7R48WJFRERoy5Yt2rp1qyTXeH59+vSRMUafffZZjtvnz5+vEiVKqHfv3sVcGW51BBk4Vbt27TR+/HgdPXpUn3zyiWN9TtfkV69erRYtWqhChQoqV66c6tSpo+eff17S1Xkt99xzjySpf//+jqH4uLg4SVf/oq5Xr562b9+uVq1aqUyZMo59c5tfkJ6erueff15+fn4qW7asHnzwQR0/fjxLmxo1aigqKirbvn8/5o1qy2mOTEpKip599lkFBgbKbrerTp06euONN3Ttl9XbbDYNHz5cS5YsUb169WS321W3bl2tWLEi5w6/xunTpzVgwAD5+vrKw8NDDRs21Mcff+zYnjlf6PDhw1q2bJmj9vzOWfDz89Mdd9yhw4cPS5KOHDkim82mN954QzNmzFBwcLDsdrv27t0rSdq3b5969eolb29veXh46O6779ZXX32V7bh79uxRu3btVLp0aVWrVk0vvfRSjqNbOb3Gly5d0qRJk1S7dm15eHjI399fERERio+P15EjR1SlShVJUkxMjON5T5o0ybF/YdeYH+3atZMkR39e+/wiIyPl4eGhX3/9Nct+4eHhqlixok6cOOFYt3z5crVs2VJly5ZV+fLl1aVLF+3ZsyffNTVv3lw1atTQ/Pnzs21LS0vTokWL1LZtWwUEBGjXrl2KiopSrVq15OHhIT8/Pz3xxBP6448/bniea1+HTDn9Lp4/f14jRoxw/B6FhITo1Vdfzdb/CxYsUJMmTVS+fHl5enqqfv36mjlzZr6eP5yHS0twur59++r555/XqlWrNGjQoBzb7NmzRw888IAaNGigyZMny2636+DBg9q8ebMk6Y477tDkyZM1YcIEPfnkk2rZsqUkqVmzZo5j/PHHH+rUqZN69+6txx9/XL6+vtet6+WXX5bNZtPYsWN1+vRpzZgxQ2FhYdq5c6dKly6d5+eXl9r+zhijBx98UOvXr9eAAQPUqFEjrVy5Us8995x+//33bKMa3377rRYvXqyhQ4eqfPnyeuutt9SzZ08dO3ZMlSpVyrWuv/76S23atNHBgwc1fPhw1axZUwsXLlRUVJTOnz+vZ555RnfccYfmzZunkSNHqlq1ao7LRZlv8nmVlpam48ePZ6snNjZWly5d0pNPPim73S5vb2/t2bNHzZs3V9WqVTVu3DiVLVtWX3zxhbp3765///vf6tGjhyQpISFBbdu21ZUrVxzt3nvvvTy9Nunp6XrggQe0du1a9e7dW88884ySk5O1evVq/fLLLwoLC9Ps2bP11FNPqUePHoqIiJAkx+XP4qjxeuLj4yUp19d35syZWrdunSIjI7VlyxaVLFlSc+bM0apVqzRv3jwFBARIkubNm6fIyEiFh4fr1Vdf1cWLFzV79my1aNFCO3bsyNckdJvNpscee0yvvPKK9uzZo7p16zq2rVixQufOnVOfPn0kXf2j5NChQ+rfv7/8/Py0Z88evffee9qzZ4+2bt1aKBOLL168qNatW+v333/X4MGDVb16dX333XeKjo7WyZMnNWPGDEctjz76qNq3b69XX31VkvTrr79q8+bNeuaZZ266DhQDAxSx2NhYI8n8+OOPubbx8vIyd911l+PxxIkTzd9/PN98800jyZw5cybXY/z4449GkomNjc22rXXr1kaSeffdd3Pc1rp1a8fj9evXG0mmatWqJikpybH+iy++MJLMzJkzHeuCgoJMZGTkDY95vdoiIyNNUFCQ4/GSJUuMJPPSSy9laderVy9js9nMwYMHHeskGXd39yzrfv75ZyPJvP3229nO9XczZswwkswnn3ziWHf58mXTtGlTU65cuSzPPSgoyHTp0uW6x/t72w4dOpgzZ86YM2fOmJ9//tn07t3bSDJPP/20McaYw4cPG0nG09PTnD59Osv+7du3N/Xr1zeXLl1yrMvIyDDNmjUzt912m2PdiBEjjCTz/fffO9adPn3aeHl5GUnm8OHDjvXXvh4fffSRkWSmT5+erf6MjAxjjDFnzpwxkszEiROztSmKGnOS+Xuwf/9+c+bMGXP48GEzZ84cY7fbja+vr0lJScnx+RljzMqVKx0/R4cOHTLlypUz3bt3d2xPTk42FSpUMIMGDcqyX0JCgvHy8sqy/trfx9zs2bPHSDLR0dFZ1vfu3dt4eHiYxMREY4wxFy9ezLbvZ599ZiSZTZs2OdZl/t/x937K7TW59ndxypQppmzZsua///1vlnbjxo0zJUuWNMeOHTPGGPPMM88YT09Pc+XKlRs+P7gmLi3BJZQrV+66dy9lzs9YunRpgYfl7Xa7+vfvn+f2/fr1U/ny5R2Pe/XqJX9/f33zzTcFOn9effPNNypZsqT+8Y9/ZFn/7LPPyhij5cuXZ1kfFham4OBgx+MGDRrI09NThw4duuF5/Pz89OijjzrWubm56R//+IcuXLigjRs3Fvg5rFq1SlWqVFGVKlXUsGFDLVy4UH379nX8xZupZ8+eWUZ3zp07p3Xr1unhhx9WcnKyzp49q7Nnz+qPP/5QeHi4Dhw4oN9//91R/3333ad7773XsX+VKlUcf/Vfz7///W9VrlxZTz/9dLZtNxoNKK4a/65OnTqqUqWKatasqcGDByskJETLli1TmTJlct2nQ4cOGjx4sCZPnqyIiAh5eHhozpw5ju2rV6/W+fPn9eijjzqew9mzZ1WyZEmFhoZq/fr1+apRku68807dddddWrBggWNdSkqKvvrqKz3wwAPy9PSUpCwjUpcuXdLZs2d13333SZJ++umnfJ83JwsXLlTLli1VsWLFLM8vLCxM6enp2rRpk6Sr/7ekpKRo9erVhXJeFD8uLcElXLhwQT4+Prluf+SRR/TBBx9o4MCBGjdunNq3b6+IiAj16tVLJUrkLY9XrVo1XxMib7vttiyPbTabQkJCivwzLY4ePaqAgIAsIUq6eokqc/vfVa9ePdsxKlasqD///POG57ntttuy9V9u58mP0NBQvfTSS45bhu+4444cJwvXrFkzy+ODBw/KGKPx48dr/PjxOR779OnTqlq1qo4eParQ0NBs2+vUqXPD+uLj41WnTh2VKpX//wKLq8a/+/e//y1PT0+5ubmpWrVqWYLr9bzxxhtaunSpdu7cqfnz52f5HTtw4ICk/5tvc63M0JFfffr00ejRo/Xdd9+pWbNmWrJkiS5evJglvJ07d04xMTFasGCBTp8+nWX/xMTEAp33WgcOHNCuXbtyvQyaed6hQ4fqiy++UKdOnVS1alV16NBBDz/8sDp27FgodaDoEWTgdL/99psSExMVEhKSa5vSpUtr06ZNWr9+vZYtW6YVK1bo888/V7t27bRq1SqVLFnyhue52XkJOcntr/f09PQ81VQYcjuPuWZicHGqXLmywsLCbtju2tckc7Rt9OjRCg8Pz3Gf6/2cFAdn1NiqVStVrlw53/vt2LHD8Ya9e/fuLKNvmc9j3rx58vPzy7ZvQUKeJD366KMaM2aM5s+fr2bNmmn+/PmqWLGiOnfu7Gjz8MMP67vvvtNzzz2nRo0aqVy5csrIyFDHjh0LPOKanp6e5XFGRobuv/9+jRkzJsf2tWvXliT5+Pho586dWrlypZYvX67ly5crNjZW/fr1yzLxHa6LIAOnmzdvniTl+qaQqUSJEmrfvr3at2+v6dOn65VXXtELL7yg9evXKywsrNA/eTTzL9ZMxhgdPHgwy+fdVKxYUefPn8+279GjR1WrVi3H4/zUFhQUpDVr1ig5OTnLqMy+ffsc2wtDUFCQdu3apYyMjCyjMoV9nvzI7DM3N7cbBqGgoKBsr5Ek7d+//4bnCQ4O1vfff6+0tDS5ubnl2Ca316y4arxZKSkp6t+/v+688041a9ZMr732mnr06OG4gy5zVMfHxydPoTOvAgIC1LZtWy1cuFDjx4/X6tWrFRUV5RgN/fPPP7V27VrFxMRowoQJjv1y6qec5PQ7d/nyZZ08eTLLuuDgYF24cCFPz83d3V1du3ZV165dlZGRoaFDh2rOnDkaP36804Mzbow5MnCqdevWacqUKapZs+Z15w2cO3cu27rMD5ZLTU2VJJUtW1aScgwWBTF37tws83YWLVqkkydPqlOnTo51wcHB2rp1a5bPP/n666+z3aadn9o6d+6s9PR0/etf/8qy/s0335TNZsty/pvRuXNnJSQk6PPPP3esu3Llit5++22VK1dOrVu3LpTz5IePj4/atGmjOXPmZHtjkqQzZ844/t25c2dt3bpVP/zwQ5btn3766Q3P07NnT509ezZbH0v/N5KVOf/k2tesuGq8WWPHjtWxY8f08ccfa/r06apRo4YiIyMdvy/h4eHy9PTUK6+8orS0tOs+j/zq06ePTp8+rcGDBystLS3L73bmCOK1I4aZdxHdSHBwsGN+S6b33nsv24jMww8/rC1btmjlypXZjnH+/HlduXJFkrLd8l2iRAnHHyuZfQXXxogMis3y5cu1b98+XblyRadOndK6deu0evVqBQUF6auvvrruB+BNnjxZmzZtUpcuXRQUFKTTp0/rnXfeUbVq1Rwfix4cHKwKFSro3XffVfny5VW2bFmFhoZmm4eRV97e3mrRooX69++vU6dOacaMGQoJCclyi/jAgQO1aNEidezYUQ8//LDi4+P1ySefZJvDkJ/aunbtqrZt2+qFF17QkSNH1LBhQ61atUpLly7ViBEj8jw/4kaefPJJzZkzR1FRUdq+fbtq1KihRYsWafPmzZoxY0a2OTrFZdasWWrRooXq16+vQYMGqVatWjp16pS2bNmi3377TT///LMkacyYMZo3b546duyoZ555xnFrc+ZI0/X069dPc+fO1ahRo/TDDz+oZcuWSklJ0Zo1azR06FB169ZNpUuX1p133qnPP/9ctWvXlre3t+rVq6d69eoVS403Y926dXrnnXc0ceJEx1cCxMbGqk2bNho/frxee+01eXp6avbs2erbt68aN26s3r17q0qVKjp27JiWLVum5s2b5xj08qJnz54aOnSoli5dqsDAQLVq1cqxzdPTU61atdJrr72mtLQ0Va1aVatWrXJ8Js6NDBw4UEOGDFHPnj11//336+eff9bKlSuzXXp77rnnHJOMo6Ki1KRJE6WkpGj37t1atGiRjhw5osqVK2vgwIE6d+6c2rVrp2rVquno0aN6++231ahRI8d8Mbg4J94xhf8RmbdQZi7u7u7Gz8/P3H///WbmzJlZbvPNdO3tnmvXrjXdunUzAQEBxt3d3QQEBJhHH300262VS5cuNXfeeacpVapUltudW7duberWrZtjfbndfv3ZZ5+Z6Oho4+PjY0qXLm26dOlijh49mm3/f/7zn6Zq1arGbreb5s2bm23btuV4O2xutV17+7UxV2+NHTlypAkICDBubm7mtttuM6+//rrj1uBMksywYcOy1ZTbbeHXOnXqlOnfv7+pXLmycXd3N/Xr18/xFvH83n59o7aZt1+//vrrOW6Pj483/fr1M35+fsbNzc1UrVrVPPDAA2bRokVZ2u3atcu0bt3aeHh4mKpVq5opU6aYDz/88Ia3Xxtz9RbgF154wdSsWdO4ubkZPz8/06tXLxMfH+9o891335kmTZoYd3f3bLf9FnaNOcn8Pbjexw5c+/ySkpJMUFCQady4sUlLS8vSbuTIkaZEiRJmy5YtjnXr16834eHhxsvLy3h4eJjg4GATFRVltm3blq2O/HjooYeMJDNmzJhs23777TfTo0cPU6FCBePl5WUeeughc+LEiWx9nNPt1+np6Wbs2LGmcuXKpkyZMiY8PNwcPHgwx5/55ORkEx0dbUJCQoy7u7upXLmyadasmXnjjTfM5cuXjTHGLFq0yHTo0MH4+PgYd3d3U716dTN48GBz8uTJfD1fOI/NGCfOCAQAALgJzJEBAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWdct/IF5GRoZOnDih8uXLF/pH2AMAgKJhjFFycrICAgKu++XAt3yQOXHihAIDA51dBgAAKIDjx4+rWrVquW6/5YNM5sesHz9+vMBfSw8AAIpXUlKSAgMDb/h1Kbd8kMm8nOTp6UmQAQDAYm40LYTJvgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLJKObsAAADgmmqMW3bDNkemdSmGSnLHiAwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAspwaZ2bNnq0GDBvL09JSnp6eaNm2q5cuXO7a3adNGNpstyzJkyBAnVgwAAFyJU7+ioFq1apo2bZpuu+02GWP08ccfq1u3btqxY4fq1q0rSRo0aJAmT57s2KdMmTLOKhcAALgYpwaZrl27Znn88ssva/bs2dq6dasjyJQpU0Z+fn7OKA8AALg4l5kjk56ergULFiglJUVNmzZ1rP/0009VuXJl1atXT9HR0bp48eJ1j5OamqqkpKQsCwAAuDU5/duvd+/eraZNm+rSpUsqV66cvvzyS915552SpMcee0xBQUEKCAjQrl27NHbsWO3fv1+LFy/O9XhTp05VTExMcZUPAACcyGaMMc4s4PLlyzp27JgSExO1aNEiffDBB9q4caMjzPzdunXr1L59ex08eFDBwcE5Hi81NVWpqamOx0lJSQoMDFRiYqI8PT2L7HkAAHCrqTFu2Q3bHJnWpUjOnZSUJC8vrxu+fzt9RMbd3V0hISGSpCZNmujHH3/UzJkzNWfOnGxtQ0NDJem6QcZut8tutxddwQAAwGW4zByZTBkZGVlGVP5u586dkiR/f/9irAgAALgqp47IREdHq1OnTqpevbqSk5M1f/58bdiwQStXrlR8fLzmz5+vzp07q1KlStq1a5dGjhypVq1aqUGDBs4sGwAAuAinBpnTp0+rX79+OnnypLy8vNSgQQOtXLlS999/v44fP641a9ZoxowZSklJUWBgoHr27KkXX3zRmSUDAAAX4tQg8+GHH+a6LTAwUBs3bizGagAAgNW43BwZAACAvCLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAyyLIAAAAy3JqkJk9e7YaNGggT09PeXp6qmnTplq+fLlj+6VLlzRs2DBVqlRJ5cqVU8+ePXXq1CknVgwAAFyJU4NMtWrVNG3aNG3fvl3btm1Tu3bt1K1bN+3Zs0eSNHLkSP2///f/tHDhQm3cuFEnTpxQRESEM0sGAAAuxGaMMc4u4u+8vb31+uuvq1evXqpSpYrmz5+vXr16SZL27dunO+64Q1u2bNF9992Xp+MlJSXJy8tLiYmJ8vT0LMrSAQC4pdQYt+yGbY5M61Ik587r+7fLzJFJT0/XggULlJKSoqZNm2r79u1KS0tTWFiYo83tt9+u6tWra8uWLU6sFAAAuIpSzi5g9+7datq0qS5duqRy5crpyy+/1J133qmdO3fK3d1dFSpUyNLe19dXCQkJuR4vNTVVqampjsdJSUlFVToAAHAyp4/I1KlTRzt37tT333+vp556SpGRkdq7d2+Bjzd16lR5eXk5lsDAwEKsFgAAuBKnBxl3d3eFhISoSZMmmjp1qho2bKiZM2fKz89Ply9f1vnz57O0P3XqlPz8/HI9XnR0tBITEx3L8ePHi/gZAAAAZ3F6kLlWRkaGUlNT1aRJE7m5uWnt2rWObfv379exY8fUtGnTXPe32+2O27kzFwAAcGty6hyZ6OhoderUSdWrV1dycrLmz5+vDRs2aOXKlfLy8tKAAQM0atQoeXt7y9PTU08//bSaNm2a5zuWAADArc2pQeb06dPq16+fTp48KS8vLzVo0EArV67U/fffL0l68803VaJECfXs2VOpqakKDw/XO++848ySAQCAC3G5z5EpbHyODAAABcPnyAAAABQhggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAspwaZqVOn6p577lH58uXl4+Oj7t27a//+/VnatGnTRjabLcsyZMgQJ1UMAABciVODzMaNGzVs2DBt3bpVq1evVlpamjp06KCUlJQs7QYNGqSTJ086ltdee81JFQMAAFdSypknX7FiRZbHcXFx8vHx0fbt29WqVSvH+jJlysjPz6+4ywMAAC7OpebIJCYmSpK8vb2zrP/0009VuXJl1atXT9HR0bp48aIzygMAAC7GqSMyf5eRkaERI0aoefPmqlevnmP9Y489pqCgIAUEBGjXrl0aO3as9u/fr8WLF+d4nNTUVKWmpjoeJyUlFXntAADAOVwmyAwbNky//PKLvv322yzrn3zySce/69evL39/f7Vv317x8fEKDg7OdpypU6cqJiamyOsFAADO5xKXloYPH66vv/5a69evV7Vq1a7bNjQ0VJJ08ODBHLdHR0crMTHRsRw/frzQ6wUAAK7BqSMyxhg9/fTT+vLLL7VhwwbVrFnzhvvs3LlTkuTv75/jdrvdLrvdXphlAgAAF+XUIDNs2DDNnz9fS5cuVfny5ZWQkCBJ8vLyUunSpRUfH6/58+erc+fOqlSpknbt2qWRI0eqVatWatCggTNLBwAALsCpQWb27NmSrn7o3d/FxsYqKipK7u7uWrNmjWbMmKGUlBQFBgaqZ8+eevHFF51QLQAAcDVOv7R0PYGBgdq4cWMxVQMAAKzGJSb7AgAAFARBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWBZBBgAAWFaBgsyhQ4cKuw4AAIB8K1CQCQkJUdu2bfXJJ5/o0qVLhV0TAABAnhQoyPz0009q0KCBRo0aJT8/Pw0ePFg//PBDYdcGAABwXQUKMo0aNdLMmTN14sQJffTRRzp58qRatGihevXqafr06Tpz5kxh1wkAAJDNTU32LVWqlCIiIrRw4UK9+uqrOnjwoEaPHq3AwED169dPJ0+eLKw6AQAAsrmpILNt2zYNHTpU/v7+mj59ukaPHq34+HitXr1aJ06cULdu3QqrTgAAgGxKFWSn6dOnKzY2Vvv371fnzp01d+5cde7cWSVKXM1FNWvWVFxcnGrUqFGYtQIAAGRRoCAze/ZsPfHEE4qKipK/v3+ObXx8fPThhx/eVHEAAADXU6Ags3r1alWvXt0xApPJGKPjx4+revXqcnd3V2RkZKEUCQAAkJMCzZEJDg7W2bNns60/d+6catasedNFAQAA5EWBgowxJsf1Fy5ckIeHx00VBAAAkFf5urQ0atQoSZLNZtOECRNUpkwZx7b09HR9//33atSoUZ6PN3XqVC1evFj79u1T6dKl1axZM7366quqU6eOo82lS5f07LPPasGCBUpNTVV4eLjeeecd+fr65qd0AABwC8pXkNmxY4ekqyMyu3fvlru7u2Obu7u7GjZsqNGjR+f5eBs3btSwYcN0zz336MqVK3r++efVoUMH7d27V2XLlpUkjRw5UsuWLdPChQvl5eWl4cOHKyIiQps3b85P6QAA4BZkM7ldJ7qO/v37a+bMmfL09CzUYs6cOSMfHx9t3LhRrVq1UmJioqpUqaL58+erV69ekqR9+/bpjjvu0JYtW3Tffffd8JhJSUny8vJSYmJiodcLAMCtrMa4ZTdsc2RalyI5d17fvws0RyY2NrZIQkFiYqIkydvbW5K0fft2paWlKSwszNHm9ttvV/Xq1bVly5Ycj5GamqqkpKQsCwAAuDXl+dJSRESE4uLi5OnpqYiIiOu2Xbx4cb4LycjI0IgRI9S8eXPVq1dPkpSQkCB3d3dVqFAhS1tfX18lJCTkeJypU6cqJiYm3+cHAADWk+cg4+XlJZvN5vh3YRs2bJh++eUXffvttzd1nOjoaMekZOnq0FRgYODNlgcAAFxQnoNMbGxsjv8uDMOHD9fXX3+tTZs2qVq1ao71fn5+unz5ss6fP59lVObUqVPy8/PL8Vh2u112u71Q6wMAAK6pQHNk/vrrL128eNHx+OjRo5oxY4ZWrVqVr+MYYzR8+HB9+eWXWrduXbYP02vSpInc3Ny0du1ax7r9+/fr2LFjatq0aUFKBwAAt5ACfUVBt27dFBERoSFDhuj8+fO699575e7urrNnz2r69Ol66qmn8nScYcOGaf78+Vq6dKnKly/vmPfi5eWl0qVLy8vLSwMGDNCoUaPk7e0tT09PPf3002ratGme7lgCAAC3tgKNyPz0009q2bKlJGnRokXy8/PT0aNHNXfuXL311lt5Ps7s2bOVmJioNm3ayN/f37F8/vnnjjZvvvmmHnjgAfXs2VOtWrWSn59fgSYTAwCAW0+BRmQuXryo8uXLS5JWrVqliIgIlShRQvfdd5+OHj2a5+Pk5SNsPDw8NGvWLM2aNasgpQIAgFtYgUZkQkJCtGTJEh0/flwrV65Uhw4dJEmnT5/mQ+cAAECxKVCQmTBhgkaPHq0aNWooNDTUMfF21apVuuuuuwq1QAAAgNwU6NJSr1691KJFC508eVINGzZ0rG/fvr169OhRaMUBAABcT4GCjHT1M16u/SyXe++996YLAgAAyKsCBZmUlBRNmzZNa9eu1enTp5WRkZFl+6FDhwqlOAAAgOspUJAZOHCgNm7cqL59+8rf39/x1QUAAADFqUBBZvny5Vq2bJmaN29e2PUAAADkWYHuWqpYsaK8vb0LuxYAAIB8KVCQmTJliiZMmJDl+5YAAACKW4EuLf3zn/9UfHy8fH19VaNGDbm5uWXZ/tNPPxVKcQAAANdToCDTvXv3Qi4DAAAg/woUZCZOnFjYdQAAAORbgebISNL58+f1wQcfKDo6WufOnZN09ZLS77//XmjFAQAAXE+BRmR27dqlsLAweXl56ciRIxo0aJC8vb21ePFiHTt2THPnzi3sOgEAALIp0IjMqFGjFBUVpQMHDsjDw8OxvnPnztq0aVOhFQcAAHA9BQoyP/74owYPHpxtfdWqVZWQkHDTRQEAAORFgYKM3W5XUlJStvX//e9/VaVKlZsuCgAAIC8KFGQefPBBTZ48WWlpaZIkm82mY8eOaezYserZs2ehFggAAJCbAgWZf/7zn7pw4YKqVKmiv/76S61bt1ZISIjKly+vl19+ubBrBAAAyFGB7lry8vLS6tWrtXnzZv3888+6cOGCGjdurLCwsMKuDwAAIFf5DjIZGRmKi4vT4sWLdeTIEdlsNtWsWVN+fn4yxshmsxVFnQAAANnk69KSMUYPPvigBg4cqN9//13169dX3bp1dfToUUVFRalHjx5FVScAAEA2+RqRiYuL06ZNm7R27Vq1bds2y7Z169ape/fumjt3rvr161eoRQIAAOQkXyMyn332mZ5//vlsIUaS2rVrp3HjxunTTz8ttOIAAACuJ19BZteuXerYsWOu2zt16qSff/75posCAADIi3wFmXPnzsnX1zfX7b6+vvrzzz9vuigAAIC8yFeQSU9PV6lSuU+rKVmypK5cuXLTRQEAAORFvib7GmMUFRUlu92e4/bU1NRCKQoAACAv8hVkIiMjb9iGO5YAAEBxyVeQiY2NLao6AAAA8q1A37UEAADgCggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAspwaZDZt2qSuXbsqICBANptNS5YsybI9KipKNpsty3K9L60EAAD/W5waZFJSUtSwYUPNmjUr1zYdO3bUyZMnHctnn31WjBUCAABXlq9P9i1snTp1UqdOna7bxm63y8/Pr5gqAgAAVuLyc2Q2bNggHx8f1alTR0899ZT++OOP67ZPTU1VUlJSlgUAANyaXDrIdOzYUXPnztXatWv16quvauPGjerUqZPS09Nz3Wfq1Kny8vJyLIGBgcVYMQAAKE5OvbR0I71793b8u379+mrQoIGCg4O1YcMGtW/fPsd9oqOjNWrUKMfjpKQkwgwAALcolx6RuVatWrVUuXJlHTx4MNc2drtdnp6eWRYAAHBrslSQ+e233/THH3/I39/f2aUAAAAX4NRLSxcuXMgyunL48GHt3LlT3t7e8vb2VkxMjHr27Ck/Pz/Fx8drzJgxCgkJUXh4uBOrBgAArsKpQWbbtm1q27at43Hm3JbIyEjNnj1bu3bt0scff6zz588rICBAHTp00JQpU2S3251VMgAAcCFODTJt2rSRMSbX7StXrizGagAAgNVYao4MAADA3xFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZTk1yGzatEldu3ZVQECAbDablixZkmW7MUYTJkyQv7+/SpcurbCwMB04cMA5xQIAAJfj1CCTkpKihg0batasWTluf+211/TWW2/p3Xff1ffff6+yZcsqPDxcly5dKuZKAQCAKyrlzJN36tRJnTp1ynGbMUYzZszQiy++qG7dukmS5s6dK19fXy1ZskS9e/cuzlIBAIALctk5MocPH1ZCQoLCwsIc67y8vBQaGqotW7bkul9qaqqSkpKyLAAA4NbkskEmISFBkuTr65tlva+vr2NbTqZOnSovLy/HEhgYWKR1AgAA53HZIFNQ0dHRSkxMdCzHjx93dkkAAKCIuGyQ8fPzkySdOnUqy/pTp045tuXEbrfL09MzywIAAG5NLhtkatasKT8/P61du9axLikpSd9//72aNm3qxMoAAICrcOpdSxcuXNDBgwcdjw8fPqydO3fK29tb1atX14gRI/TSSy/ptttuU82aNTV+/HgFBASoe/fuzisaAAC4DKcGmW3btqlt27aOx6NGjZIkRUZGKi4uTmPGjFFKSoqefPJJnT9/Xi1atNCKFSvk4eHhrJIBAIALsRljjLOLKEpJSUny8vJSYmIi82UAAMiHGuOW3bDNkWldiuTceX3/dtk5MgAAADdCkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZFkAEAAJZVytkFWJkzv94cAAAwIgMAACyMIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACyLIAMAACzLpYPMpEmTZLPZsiy33367s8sCAAAuopSzC7iRunXras2aNY7HpUq5fMkAAKCYuHwqKFWqlPz8/JxdBgAAcEEufWlJkg4cOKCAgADVqlVLffr00bFjx5xdEgAAcBEuPSITGhqquLg41alTRydPnlRMTIxatmypX375ReXLl89xn9TUVKWmpjoeJyUlFVe5AACgmLl0kOnUqZPj3w0aNFBoaKiCgoL0xRdfaMCAATnuM3XqVMXExBRXiQAAwIlc/tLS31WoUEG1a9fWwYMHc20THR2txMREx3L8+PFirBAAABQnSwWZCxcuKD4+Xv7+/rm2sdvt8vT0zLIAAIBbk0sHmdGjR2vjxo06cuSIvvvuO/Xo0UMlS5bUo48+6uzSAACAC3DpOTK//fabHn30Uf3xxx+qUqWKWrRooa1bt6pKlSrOLg0AALgAlw4yCxYscHYJAADAhbn0pSUAAIDrIcgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLKuXsAgAAQPGrMW6Zs0soFIzIAAAAyyLIAAAAy+LSUhHLy9DdkWldiqESAABuPYzIAAAAy7LEiMysWbP0+uuvKyEhQQ0bNtTbb7+te++919llAQDgkm6Vibx54fJB5vPPP9eoUaP07rvvKjQ0VDNmzFB4eLj2798vHx8fZ5dXKPL6A8clKAAAsrIZY4yzi7ie0NBQ3XPPPfrXv/4lScrIyFBgYKCefvppjRs37ob7JyUlycvLS4mJifL09CzU2lwx8RJ2AODW5mrvPUX1vpPX92+XHpG5fPmytm/frujoaMe6EiVKKCwsTFu2bHFiZa6rsH7ACUQAkHeuFi7+l7h0kDl79qzS09Pl6+ubZb2vr6/27duX4z6pqalKTU11PE5MTJR0NdkVtozUi4V+TFdRfeRCZ5cAALCAonh//ftxb3ThyKWDTEFMnTpVMTEx2dYHBgY6oRoAAG5tXjOK9vjJycny8vLKdbtLB5nKlSurZMmSOnXqVJb1p06dkp+fX477REdHa9SoUY7HGRkZOnfunCpVqiSbzVZotSUlJSkwMFDHjx8v9Lk3yIq+Lh70c/Ghr4sH/Vw8iqqfjTFKTk5WQEDAddu5dJBxd3dXkyZNtHbtWnXv3l3S1WCydu1aDR8+PMd97Ha77HZ7lnUVKlQosho9PT35BSkm9HXxoJ+LD31dPOjn4lEU/Xy9kZhMLh1kJGnUqFGKjIzU3XffrXvvvVczZsxQSkqK+vfv7+zSAACAk7l8kHnkkUd05swZTZgwQQkJCWrUqJFWrFiRbQIwAAD43+PyQUaShg8fnuulJGex2+2aOHFitstYKHz0dfGgn4sPfV086Ofi4ex+dvkPxAMAAMgNXxoJAAAsiyADAAAsiyADAAAsiyADAAAsiyBzHbNmzVKNGjXk4eGh0NBQ/fDDD9dtv3DhQt1+++3y8PBQ/fr19c033xRTpdaXn75+//331bJlS1WsWFEVK1ZUWFjYDV8bXJXfn+lMCxYskM1mc3wwJa4vv/18/vx5DRs2TP7+/rLb7apduzb/f+RRfvt6xowZqlOnjkqXLq3AwECNHDlSly5dKqZqrWnTpk3q2rWrAgICZLPZtGTJkhvus2HDBjVu3Fh2u10hISGKi4srugINcrRgwQLj7u5uPvroI7Nnzx4zaNAgU6FCBXPq1Kkc22/evNmULFnSvPbaa2bv3r3mxRdfNG5ubmb37t3FXLn15LevH3vsMTNr1iyzY8cO8+uvv5qoqCjj5eVlfvvtt2Ku3Fry28+ZDh8+bKpWrWpatmxpunXrVjzFWlh++zk1NdXcfffdpnPnzubbb781hw8fNhs2bDA7d+4s5sqtJ799/emnnxq73W4+/fRTc/jwYbNy5Urj7+9vRo4cWcyVW8s333xjXnjhBbN48WIjyXz55ZfXbX/o0CFTpkwZM2rUKLN3717z9ttvm5IlS5oVK1YUSX0EmVzce++9ZtiwYY7H6enpJiAgwEydOjXH9g8//LDp0qVLlnWhoaFm8ODBRVrnrSC/fX2tK1eumPLly5uPP/64qEq8JRSkn69cuWKaNWtmPvjgAxMZGUmQyYP89vPs2bNNrVq1zOXLl4urxFtGfvt62LBhpl27dlnWjRo1yjRv3rxI67yV5CXIjBkzxtStWzfLukceecSEh4cXSU1cWsrB5cuXtX37doWFhTnWlShRQmFhYdqyZUuO+2zZsiVLe0kKDw/PtT2uKkhfX+vixYtKS0uTt7d3UZVpeQXt58mTJ8vHx0cDBgwojjItryD9/NVXX6lp06YaNmyYfH19Va9ePb3yyitKT08vrrItqSB93axZM23fvt1x+enQoUP65ptv1Llz52Kp+X9Fcb8fWuKTfYvb2bNnlZ6enu1rEHx9fbVv374c90lISMixfUJCQpHVeSsoSF9fa+zYsQoICMj2i4P/U5B+/vbbb/Xhhx9q586dxVDhraEg/Xzo0CGtW7dOffr00TfffKODBw9q6NChSktL08SJE4ujbEsqSF8/9thjOnv2rFq0aCFjjK5cuaIhQ4bo+eefL46S/2fk9n6YlJSkv/76S6VLly7U8zEiA0ubNm2aFixYoC+//FIeHh7OLueWkZycrL59++r9999X5cqVnV3OLS0jI0M+Pj5677331KRJEz3yyCN64YUX9O677zq7tFvOhg0b9Morr+idd97RTz/9pMWLF2vZsmWaMmWKs0vDTWBEJgeVK1dWyZIlderUqSzrT506JT8/vxz38fPzy1d7XFWQvs70xhtvaNq0aVqzZo0aNGhQlGVaXn77OT4+XkeOHFHXrl0d6zIyMiRJpUqV0v79+xUcHFy0RVtQQX6e/f395ebmppIlSzrW3XHHHUpISNDly5fl7u5epDVbVUH6evz48erbt68GDhwoSapfv75SUlL05JNP6oUXXlCJEvxtXxhyez/09PQs9NEYiRGZHLm7u6tJkyZau3atY11GRobWrl2rpk2b5rhP06ZNs7SXpNWrV+faHlcVpK8l6bXXXtOUKVO0YsUK3X333cVRqqXlt59vv/127d69Wzt37nQsDz74oNq2baudO3cqMDCwOMu3jIL8PDdv3lwHDx50BEVJ+u9//yt/f39CzHUUpK8vXryYLaxkBkjD1w4WmmJ/PyySKcS3gAULFhi73W7i4uLM3r17zZNPPmkqVKhgEhISjDHG9O3b14wbN87RfvPmzaZUqVLmjTfeML/++quZOHEit1/nUX77etq0acbd3d0sWrTInDx50rEkJyc76ylYQn77+VrctZQ3+e3nY8eOmfLly5vhw4eb/fv3m6+//tr4+PiYl156yVlPwTLy29cTJ0405cuXN5999pk5dOiQWbVqlQkODjYPP/yws56CJSQnJ5sdO3aYHTt2GElm+vTpZseOHebo0aPGGGPGjRtn+vbt62ifefv1c889Z3799Vcza9Ysbr92lrfffttUr17duLu7m3vvvdds3brVsa1169YmMjIyS/svvvjC1K5d27i7u5u6deuaZcuWFXPF1pWfvg4KCjKSsi0TJ04s/sItJr8/039HkMm7/Pbzd999Z0JDQ43dbje1atUyL7/8srly5UoxV21N+enrtLQ0M2nSJBMcHGw8PDxMYGCgGTp0qPnzzz+Lv3ALWb9+fY7/52b2bWRkpGndunW2fRo1amTc3d1NrVq1TGxsbJHVZzOG8TQAAGBNzJEBAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABUKiioqLUvXv3QjteXFycKlSoUGjHy8mRI0dks9n4pm/AgggyAPIlKipKNptNNptN7u7uCgkJ0eTJk3XlyhVJ0syZMxUXF1cstZw6dUpubm5asGBBjtsHDBigxo0bF0stAJyDIAMg3zp27KiTJ0/qwIEDevbZZzVp0iS9/vrrkiQvL68iH0HJ5Ovrqy5duuijjz7Kti0lJUVffPGFBgwYUCy1AHAOggyAfLPb7fLz81NQUJCeeuophYWF6auvvpKU9dLSmTNn5Ofnp1deecWx73fffSd3d3fHt+OmpqZq9OjRqlq1qsqWLavQ0FBt2LAhz7UMGDBAa9eu1bFjx7KsX7hwoa5cuaI+ffpoxYoVatGihSpUqKBKlSrpgQceUHx8fK7HzOly1pIlS2Sz2bKsW7p0qRo3biwPDw/VqlVLMTExjpEpAMWDIAPgppUuXVqXL1/Otr5KlSr66KOPNGnSJG3btk3Jycnq27evhg8frvbt20uShg8fri1btmjBggXatWuXHnroIXXs2FEHDhzI07k7d+4sX1/fbJezYmNjFRERoQoVKiglJUWjRo3Stm3btHbtWpUoUUI9evRQRkZGgZ/zf/7zH/Xr10/PPPOM9u7dqzlz5iguLk4vv/xygY8JIP8IMgAKzBijNWvWaOXKlWrXrl2ObTp37qxBgwapT58+GjJkiMqWLaupU6dKko4dO6bY2FgtXLhQLVu2VHBwsEaPHq0WLVooNjY2TzWULFlSkZGRiouLU+Z34MbHx+s///mPnnjiCUlSz549FRERoZCQEDVq1EgfffSRdu/erb179xb4ucfExGjcuHGKjIxUrVq1dP/992vKlCmaM2dOgY8JIP9KObsAANbz9ddfq1y5ckpLS1NGRoYee+wxTZo0Kdf2b7zxhurVq6eFCxdq+/btstvtkqTdu3crPT1dtWvXztI+NTVVlSpVynM9TzzxhKZNm6b169erXbt2io2NVY0aNRzh6sCBA5owYYK+//57nT171jESc+zYMdWrVy+fz/6qn3/+WZs3b84yApOenq5Lly7p4sWLKlOmTIGOCyB/CDIA8q1t27aaPXu23N3dFRAQoFKlrv9fSXx8vE6cOKGMjAwdOXJE9evXlyRduHBBJUuW1Pbt21WyZMks+5QrVy7P9dx2221q2bKlYmNj1aZNG82dO1eDBg1yzGnp2rWrgoKC9P777ysgIEAZGRmqV69ejpfDJKlEiRKO0Z1MaWlpWR5fuHBBMTExioiIyLa/h4dHnmsHcHMIMgDyrWzZsgoJCclT28uXL+vxxx/XI488ojp16mjgwIHavXu3fHx8dNdddyk9PV2nT59Wy5Ytb6qmAQMG6KmnntKDDz6o33//XVFRUZKkP/74Q/v379f777/vOMe333573WNVqVJFycnJSklJUdmyZSUp22fMNG7cWPv3789zPwAoGsyRAVCkXnjhBSUmJuqtt97S2LFjVbt2bcfcldq1a6tPnz7q16+fFi9erMOHD+uHH37Q1KlTtWzZsnyd56GHHpKbm5sGDx6sDh06KDAwUJJUsWJFVapUSe+9954OHjyodevWadSoUdc9VmhoqMqUKaPnn39e8fHxmj9/frbJxBMmTNDcuXMVExOjPXv26Ndff9WCBQv04osv5qtuADeHIAOgyGzYsEEzZszQvHnz5OnpqRIlSmjevHn6z3/+o9mzZ0u6endRv3799Oyzz6pOnTrq3r27fvzxR1WvXj1f5ypTpox69+6tP//80xGUpKuXiRYsWKDt27erXr16GjlypOMzb3Lj7e2tTz75RN98843q16+vzz77LNscoPDwcH399ddatWqV7rnnHt1333168803FRQUlK+6Adwcm7n2QjAAAIBFMCIDAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAs6/8DHxoniMwDzpYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ7G9O_K69Hr"
      },
      "source": [
        "## Display Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqMBAVWcLDln"
      },
      "outputs": [],
      "source": [
        "def display_results(image, ground_truth_mask, predicted_mask):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Display input image\n",
        "    axes[0].imshow(np.transpose(image, (1, 2, 0)))\n",
        "    axes[0].set_title('Input Image')\n",
        "\n",
        "    # Display ground truth mask\n",
        "    axes[1].imshow(np.squeeze(ground_truth_mask))\n",
        "    axes[1].set_title('Ground Truth Mask')\n",
        "\n",
        "    # Display predicted mask\n",
        "    axes[2].imshow(np.squeeze(predicted_mask))\n",
        "    axes[2].set_title('Predicted Mask')\n",
        "\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_jbuq7iE354B",
        "dRB5U53vS6NK",
        "ihXq1aKcZuVQ",
        "IawsoiuQBxU3"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}